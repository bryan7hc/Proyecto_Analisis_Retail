# Activar entorno virtual
.\.venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt


# ğŸ“Š Proyecto de AnÃ¡lisis Retail â€” Dashboard + ETL + PostgreSQL

Este proyecto implementa un flujo completo de **AnÃ¡lisis de Datos**, desde la ingesta del dataset crudo, su transformaciÃ³n mediante un pipeline ETL, la carga a una base de datos PostgreSQL, hasta la visualizaciÃ³n interactiva mediante un dashboard construido en **Streamlit**.

El objetivo principal es demostrar habilidades profesionales en:

* Limpieza y transformaciÃ³n de datos (ETL)
* Modelado y carga en base de datos
* Desarrollo de dashboards analÃ­ticos
* OrganizaciÃ³n modular de proyectos
* ConexiÃ³n entre Python, SQL y aplicaciones interactivas

---

## ğŸ—‚ï¸ Arquitectura General del Proyecto

```
proyecto_analisis_retail/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ superstore.csv
â”‚   â””â”€â”€ clean_superstore.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚     â””â”€â”€ prepare_data.py
â”‚   â””â”€â”€ dashboard/
â”‚         â””â”€â”€ app_streamlit.py
â”‚
â”œâ”€â”€ .venv/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### ğŸ“ `data/`

Contiene los datasets utilizados:

* **superstore.csv:** dataset crudo, tal cual fue descargado.
* **clean_superstore.csv:** dataset limpio generado automÃ¡ticamente por el ETL.

### ğŸ“ `src/transform/prepare_data.py`

Este archivo implementa el pipeline ETL:

1. **Extract:** carga el CSV crudo desde `data/superstore.csv`.
2. **Transform:**

   * Limpieza de nombres de columnas.
   * ConversiÃ³n de tipos (fechas, numÃ©ricos, cadenas).
   * CÃ¡lculo de nuevas mÃ©tricas: profit margin, days to ship, aÃ±o y mes de orden.
   * Manejo de encoding (`latin1`) y valores corruptos.
3. **Load:** carga el dataframe limpio a PostgreSQL como la tabla `superstore_clean`.

Este proceso garantiza que los datos estÃ©n listos para anÃ¡lisis y visualizaciÃ³n.

### ğŸ“ `src/dashboard/app_streamlit.py`

AplicaciÃ³n visual interactiva construida con Streamlit. Se encarga de:

* Conectarse a PostgreSQL.
* Ejecutar consultas dinÃ¡micas.
* Mostrar KPIs (ventas, profit, margen, Ã³rdenes).
* Visualizar grÃ¡ficos:

  * Ventas por mes
  * Profit por categorÃ­a
  * Top productos
* Mostrar una tabla final filtrable.

La aplicaciÃ³n permite un anÃ¡lisis exploratorio completo.

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### **Backend y ETL**

* Python 3.x
* Pandas
* SQLAlchemy
* Psycopg2
* Python-Decouple

### **Base de Datos**

* PostgreSQL 18
* Esquema `public`
* Tabla: `superstore_clean`

### **Dashboard**

* Streamlit
* Plotly (visualizaciones)

### **Entorno de desarrollo**

* Visual Studio Code
* Entorno virtual `.venv`

---

## ğŸš€ Flujo Completo del Proyecto

```
superstore.csv (crudo)
      â”‚
      â–¼
prepare_data.py (ETL)
      â”‚
      â–¼
clean_superstore.csv (procesado)
      â”‚
      â–¼
PostgreSQL â†’ superstore_clean
      â”‚
      â–¼
Streamlit â†’ Dashboard Interactivo
```

Este flujo demuestra conocimientos en ingenierÃ­a de datos, visualizaciÃ³n e integraciÃ³n.

---

## â–¶ï¸ CÃ³mo Encender el Proyecto

### 1. Activar entorno virtual

```
.\.venv\Scripts\Activate.ps1
```

### 2. Instalar dependencias

```
pip install -r requirements.txt
```

### 3. Ejecutar ETL

```
python src/transform/prepare_data.py
```

### 4. Encender dashboard

```
streamlit run src/dashboard/app_streamlit.py
```

---

## ğŸ“Œ Objetivo del Proyecto en Portafolio

Este proyecto fue diseÃ±ado para demostrar:

* Competencia sÃ³lida en anÃ¡lisis de datos.
* Capacidad para trabajar con infraestructura real (bases de datos + Python).
* Buenas prÃ¡cticas en organizaciÃ³n de proyectos.
* Habilidad para entregar soluciones visuales comprensibles y funcionales.

Es un proyecto ideal para aplicar a posiciones de:

* Data Analyst
* Business Intelligence
* Data Engineer (nivel junior)
* Data Science (nivel inicial)

---

## ğŸ“ Contacto

*AquÃ­ puedes agregar tus redes, correo o portafolio personal.*
